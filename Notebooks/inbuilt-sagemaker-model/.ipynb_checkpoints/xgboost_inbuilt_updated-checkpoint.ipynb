{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker-experiments\n",
      "  Using cached sagemaker_experiments-0.1.30-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.17.55)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.4.1)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.55 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.20.55)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.55->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.55->boto3>=1.16.27->sagemaker-experiments) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.55->boto3>=1.16.27->sagemaker-experiments) (1.15.0)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.30\n",
      "Requirement already satisfied: s3fs in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.4.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from s3fs) (1.20.55)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from s3fs) (0.8.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (1.26.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs) (0.10.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from fsspec>=0.6.0->s3fs) (3.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata->fsspec>=0.6.0->s3fs) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata->fsspec>=0.6.0->s3fs) (3.4.0)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (3.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: seaborn in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.11.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from seaborn) (1.18.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from seaborn) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Collecting shap\n",
      "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
      "\u001b[K     |████████████████████████████████| 356 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap) (1.18.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap) (0.24.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap) (1.1.5)\n",
      "Collecting tqdm>4.25.0\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 8.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap) (0.52.0)\n",
      "Requirement already satisfied: cloudpickle in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from numba->shap) (0.35.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from numba->shap) (49.6.0.post20210108)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn->shap) (1.0.1)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.39.0-cp36-cp36m-linux_x86_64.whl size=419939 sha256=24e478d4895b5312cfa8b105e723ff0c887064d6041697003b0acd3745cd25e0\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6f/08/25/2992725334291786ea084e06cac493d93049b80e3470318a1b\n",
      "Successfully built shap\n",
      "Installing collected packages: tqdm, slicer, shap\n",
      "Successfully installed shap-0.39.0 slicer-0.0.7 tqdm-4.60.0\n",
      "Collecting smdebug\n",
      "  Downloading smdebug-1.0.8-py2.py3-none-any.whl (263 kB)\n",
      "\u001b[K     |████████████████████████████████| 263 kB 22.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smdebug) (3.15.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smdebug) (1.18.5)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smdebug) (1.17.55)\n",
      "Collecting pyinstrument>=3.1.3\n",
      "  Downloading pyinstrument-3.4.1-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from smdebug) (20.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (0.4.1)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.55 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug) (1.20.55)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.55->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.55->boto3>=1.10.32->smdebug) (1.26.4)\n",
      "Requirement already satisfied: six>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.6.0->smdebug) (1.15.0)\n",
      "Collecting pyinstrument-cext>=0.2.2\n",
      "  Downloading pyinstrument_cext-0.2.4-cp36-cp36m-manylinux2010_x86_64.whl (20 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from packaging->smdebug) (2.4.7)\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, smdebug\n",
      "Successfully installed pyinstrument-3.4.1 pyinstrument-cext-0.2.4 smdebug-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments\n",
    "!pip install s3fs\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install shap\n",
    "!pip install smdebug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import time\n",
    "import s3fs\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import shap\n",
    "from scipy import stats\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-04-29 07:05:13.594 ip-172-16-36-224:5457 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.debugger import rule_configs, Rule, DebuggerHookConfig,CollectionConfig\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.session import s3_input\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import Session\n",
    "\n",
    "from smdebug.trials  import create_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 2021-04-29--07-05-13\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%Y-%m-%d--%H-%M-%S\")\n",
    "print(\"current_time:\",current_time)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = '1905-assignment2-sm'\n",
    "prefix = 'Scikit-pre-model-Inference-Pipelines'\n",
    "\n",
    "train_data = 's3://1905-assignment2-sm/housing/imput-datasets/train_data_without_header.csv'\n",
    "test_data = 's3://1905-assignment2-sm/housing/imput-datasets/test_data_without_header.csv'\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "script_path = 'sklearn_pipeline.py'\n",
    "dependency_path ='dependencies.py'\n",
    "\n",
    "base_job_name = f\"Builtin-XGB-algo-{current_time}\"\n",
    "\n",
    "output_data_prefix = f'housing/datasets/output/{base_job_name}'\n",
    "data_output_path = f's3://{bucket}/{output_data_prefix}'\n",
    "\n",
    "debug_prefix = f'housing/jobs/debug/{base_job_name}'\n",
    "debug_path = f's3://{bucket}/{debug_prefix}'\n",
    "\n",
    "experiment_name_prefix = \"builtin-xgboost-track13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://1905-assignment2-sm/housing/imput-datasets/train_data_without_header.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::752400441523:role/Sagemaker_Access'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point = script_path,\n",
    "    role = role,\n",
    "    framework_version = FRAMEWORK_VERSION,\n",
    "    train_instance_type =  \"ml.m5.xlarge\", #\"local\" ,\n",
    "    train_use_spot_instance = True,\n",
    "    train_max_run = 600,\n",
    "   # train_max_wait = 1200,\n",
    "    dependencies = [dependency_path],\n",
    "    sagemaker_session = sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::752400441523:role/Sagemaker_Access'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: Builtin-XGB-algo-2021-04-29--07-05-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 07:05:14 Starting - Starting the training job...\n",
      "2021-04-29 07:05:25 Starting - Launching requested ML instancesProfilerReport-1619679914: InProgress\n",
      ".........\n",
      "2021-04-29 07:07:11 Starting - Preparing the instances for training......\n",
      "2021-04-29 07:08:11 Downloading - Downloading input data...\n",
      "2021-04-29 07:08:41 Training - Training image download completed. Training in progress.\n",
      "2021-04-29 07:08:41 Uploading - Uploading generated training model\u001b[34m2021-04-29 07:08:36,932 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:36,935 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:36,943 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:37,232 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:37,243 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:37,254 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:37,263 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"Builtin-XGB-algo-2021-04-29--07-05-13\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-752400441523/Builtin-XGB-algo-2021-04-29--07-05-13/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sklearn_pipeline\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sklearn_pipeline.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sklearn_pipeline.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sklearn_pipeline\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-752400441523/Builtin-XGB-algo-2021-04-29--07-05-13/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"Builtin-XGB-algo-2021-04-29--07-05-13\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-752400441523/Builtin-XGB-algo-2021-04-29--07-05-13/source/sourcedir.tar.gz\",\"module_name\":\"sklearn_pipeline\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sklearn_pipeline.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python sklearn_pipeline.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m*********************\u001b[0m\n",
      "\u001b[34m*****Executing numeric transformer******\u001b[0m\n",
      "\u001b[34m*****Executing categorical transformer*****\u001b[0m\n",
      "\u001b[34m*****Executing Column Transformer*****\u001b[0m\n",
      "\u001b[34mpreprocessor\u001b[0m\n",
      "\u001b[34mColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('simpleimputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('combinedattributesadder',\n",
      "                                                  CombinedAttributesAdder()),\n",
      "                                                 ('standardscaler',\n",
      "                                                  StandardScaler())]),\n",
      "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f8074a66c50>),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('simpleimputer',\n",
      "                                                  SimpleImputer(fill_value='missing',\n",
      "                                                                strategy='constant')),\n",
      "                                                 ('onehotencoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f8074a66c10>)])\u001b[0m\n",
      "\u001b[34m*****Executing FIT*****\u001b[0m\n",
      "\u001b[34mIndex(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'ocean_proximity'],\n",
      "      dtype='object')\u001b[0m\n",
      "\u001b[34msaved model!\u001b[0m\n",
      "\u001b[34m2021-04-29 07:08:38,822 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-04-29 07:09:11 Completed - Training job completed\n",
      "Training seconds: 56\n",
      "Billable seconds: 56\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit(\n",
    "    inputs={'train':train_data},\n",
    "    job_name=base_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-scikit-learn-2021-04-29-07-09-26-986\n"
     ]
    }
   ],
   "source": [
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    assemble_with = 'Line',\n",
    "    accept = 'text/csv',\n",
    "    output_path=data_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: Builtin-XGB-algo-2021-04-29--07-05-13-train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      ".\u001b[34m2021-04-29 07:13:52,028 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,030 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,031 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,028 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,030 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,031 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=e96c8e35d78dea32a11c565a46a1a790c7b8be7ffb997cf021cd45d5fef3c547\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-rk3ob174/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=e96c8e35d78dea32a11c565a46a1a790c7b8be7ffb997cf021cd45d5fef3c547\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-rk3ob174/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[35mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:56,718 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:56,718 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m*****model function*****\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m*****predict function*****\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m*****output function*****\u001b[0m\n",
      "\u001b[35m*****model function*****\u001b[0m\n",
      "\u001b[35m/opt/ml/model\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m*****predict function*****\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[35m*****output function*****\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"POST /invocations HTTP/1.1\" 200 4065423 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"POST /invocations HTTP/1.1\" 200 4065423 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-04-29T07:13:57.235:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Waiting for transform job:Builtin-XGB-algo-2021-04-29--07-05-13-train\n",
      "\u001b[34m2021-04-29 07:13:52,028 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,030 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,031 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,028 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,030 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,031 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=e96c8e35d78dea32a11c565a46a1a790c7b8be7ffb997cf021cd45d5fef3c547\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-rk3ob174/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:52,213 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=e96c8e35d78dea32a11c565a46a1a790c7b8be7ffb997cf021cd45d5fef3c547\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-rk3ob174/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[35mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:13:54 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[35mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [44] [INFO] Booting worker with pid: 44\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:13:54 +0000] [45] [INFO] Booting worker with pid: 45\u001b[0m\n",
      "\u001b[34m2021-04-29 07:13:56,718 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:13:56,718 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m*****model function*****\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m*****predict function*****\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m*****output function*****\u001b[0m\n",
      "\u001b[35m*****model function*****\u001b[0m\n",
      "\u001b[35m/opt/ml/model\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m*****predict function*****\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[35m*****output function*****\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"POST /invocations HTTP/1.1\" 200 4065423 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:13:57 +0000] \"POST /invocations HTTP/1.1\" 200 4065423 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-04-29T07:13:57.235:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=train_data,\n",
    "    content_type=\"text/csv\",\n",
    "    job_name=base_job_name+'-train')\n",
    "\n",
    "print(\"Waiting for transform job:\" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_data = transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://1905-assignment2-sm/housing/datasets/output/Builtin-XGB-algo-2021-04-29--07-05-13'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: Builtin-XGB-algo-2021-04-29--07-05-13-test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34m2021-04-29 07:18:39,155 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,158 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,158 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,350 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=2fab8a617a2f911ac06ae7492b6c7bf07baea0e26afee14cad0cd1689d1992b6\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-h_xyzfb9/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:43,960 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m*****model function*****\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:18:44 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:44,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m*****model function*****\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:18:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m*****predict function*****\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m*****output function*****\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:18:45 +0000] \"POST /invocations HTTP/1.1\" 200 1035382 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-04-29T07:18:45.000:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "Waiting for transform job:Builtin-XGB-algo-2021-04-29--07-05-13-test\n",
      "\u001b[34m2021-04-29 07:18:39,155 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,155 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,158 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,158 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:39,350 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,158 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,158 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Module sklearn_pipeline does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,349 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:39,350 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=2fab8a617a2f911ac06ae7492b6c7bf07baea0e26afee14cad0cd1689d1992b6\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-h_xyzfb9/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2021-04-29 07:18:41 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: sklearn-pipeline\n",
      "  Building wheel for sklearn-pipeline (setup.py): started\n",
      "  Building wheel for sklearn-pipeline (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-pipeline: filename=sklearn_pipeline-1.0.0-py2.py3-none-any.whl size=7409 sha256=2fab8a617a2f911ac06ae7492b6c7bf07baea0e26afee14cad0cd1689d1992b6\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-h_xyzfb9/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built sklearn-pipeline\u001b[0m\n",
      "\u001b[35mInstalling collected packages: sklearn-pipeline\u001b[0m\n",
      "\u001b[35mSuccessfully installed sklearn-pipeline-1.0.0\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [36] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [36] [INFO] Listening at: unix:/tmp/gunicorn.sock (36)\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [36] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[35m[2021-04-29 07:18:41 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:43,960 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:43,960 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m*****model function*****\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:18:44 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021-04-29 07:18:44,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m*****model function*****\u001b[0m\n",
      "\u001b[34m/opt/ml/model\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:18:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m*****predict function*****\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m*****output function*****\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [29/Apr/2021:07:18:45 +0000] \"POST /invocations HTTP/1.1\" 200 1035382 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m*****model function*****\u001b[0m\n",
      "\u001b[35m/opt/ml/model\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:18:44 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021-04-29 07:18:44,498 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m*****model function*****\u001b[0m\n",
      "\u001b[35m/opt/ml/model\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:18:44 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m*****predict function*****\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[35m*****output function*****\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [29/Apr/2021:07:18:45 +0000] \"POST /invocations HTTP/1.1\" 200 1035382 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-04-29T07:18:45.000:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=test_data,\n",
    "    content_type=\"text/csv\",\n",
    "    job_name=base_job_name+\"-test\")\n",
    "\n",
    "print(\"Waiting for transform job:\" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data = transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'housing/datasets/output/Builtin-XGB-algo-2021-04-29--07-05-13'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{output_data_prefix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload processed data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "obj = client.get_object(Bucket=bucket, Key = f'{output_data_prefix}/train_data_without_header.csv.out')\n",
    "body = obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "processed_train_data = pd.read_csv(StringIO(csv_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'processed_train_data.csv'\n",
    "processed_train_data.to_csv(train_file,index=False,header=False)\n",
    "with open(train_file,'rb') as data:\n",
    "    boto3.Session().resource('s3').Bucket(bucket).upload_fileobj(data,os.path.join(output_data_prefix,'processed-train-data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = client.get_object(Bucket=bucket, Key = f'{output_data_prefix}/test_data_without_header.csv.out')\n",
    "body = obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "processed_test_data = pd.read_csv(StringIO(csv_string))\n",
    "\n",
    "test_file = 'processed_test_data.csv'\n",
    "processed_test_data.to_csv(test_file,index=False,header=False)\n",
    "with open(test_file,'rb') as data:\n",
    "    boto3.Session().resource('s3').Bucket(bucket).upload_fileobj(data,os.path.join(output_data_prefix,'processed-test-data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real time Prediction using endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel\n",
    "\n",
    "timestamp_prefix = current_time\n",
    "\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model()\n",
    "scikit_learn_inferencee_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}\n",
    "model_containers = [scikit_learn_inferencee_model]\n",
    "\n",
    "model_name = 'inference-pipeline-' + current_time\n",
    "endpoint_name = 'inference-pipeline-ep-' + current_time\n",
    "\n",
    "sm_model = PipelineModel(\n",
    "            name=model_name,\n",
    "            role=role,\n",
    "            models=model_containers)\n",
    "\n",
    "predictor = sm_model.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m5.xlarge',\n",
    "                           endpoint_name=endpoint_name,\n",
    "                           #data_capture_config=data_capture_config\n",
    "                           )\n",
    "\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "payload = \"-122.23,37.88,41.0,880.0,129.0,322.0,126.0,8.3252,NEAR BAY\"\n",
    "\n",
    "predictor = Predictor(\n",
    "        endpoint_name = endpoint_name,\n",
    "        sagemaker_session = sagemaker_session,\n",
    "        serializer = CSVSerializer(),\n",
    "        deserializer = JSONDeserializer(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': [{'features': [-1.3358644914093034, 1.0625114171921215, 0.9843617822955569, -0.7963234446647113, -0.9664904061190807, -0.9606541571538452, -0.9683302007899453, 2.3372729061643134, 0.6152810290729377, -0.07388883558315307, -1.073845989834207, 0.0, 0.0, 0.0, 1.0, 0.0]}]}\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(data=payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '215f8680-8a28-4feb-9008-2fead898ae7a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '215f8680-8a28-4feb-9008-2fead898ae7a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 29 Apr 2021 07:52:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete the endpoint\n",
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Track and Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "role = get_execution_role()\n",
    "region = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(region, \"xgboost\",repo_version=\"0.90-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_interval = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_type = \"text/csv\"\n",
    "train_input = s3_input(f\"s3://{bucket}/{output_data_prefix}/processed-train/processed_train_data.csv\",content_type='csv')\n",
    "validation_input = s3_input(f\"s3://{bucket}/{output_data_prefix}/processed-test/processed_test_data.csv\",content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"s3://{bucket}/{output_data_prefix}/processed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Tracker.create(display_name=\"Pre-Processing\",sagemaker_boto_client=sm) as tracker:\n",
    "    tracker.log_parameters({\n",
    "        \"Num_Imputer\" : \"SimpleImputer\",\n",
    "        \"Num_Norm\" : \"StandardScaler\",\n",
    "        \"Cat_Norm\" : \"SimpleImputer\",\n",
    "        \"Cat_Convert\" : \"OneHotEncoder\",\n",
    "        \"No_of_rows\" : str(len(train_df))\n",
    "    })\n",
    "    tracker.log_input(name=\"xgboost-track\",media_type=\"s3/uri\",value=f\"s3://{bucket}/{output_data_prefix}//processed-train/processed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_experiment = Experiment.create(\n",
    "    experiment_name = f\"{experiment_name_prefix}--{int(time.time())}\",\n",
    "    description = \"xgboost-track\",\n",
    "    sagemaker_boto_client=sm)\n",
    "print(xgboost_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component = tracker.trial_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,eta in enumerate([0.3,0.4,0.5]):\n",
    "    for j,max_depth in enumerate([2,4,6]):\n",
    "        base_name = f\"xbg-eta-{str(eta).replace('.','-')}-max-depth-{str(max_depth).replace('.','-')}\"\n",
    "        time_val = f\"time-{int(time.time())}\"\n",
    "        trial_name = base_name + \"-\" + time_val\n",
    "        xgb_trial = Trial.create(\n",
    "            trial_name=trial_name,\n",
    "            experiment_name = xgboost_experiment.experiment_name,\n",
    "            sagemaker_boto_client=sm,)\n",
    "        trial_name_map[(eta,max_depth)] = trial_name\n",
    "        \n",
    "        #associate preprocessing trial component with current trial\n",
    "        xgb_trial.add_trial_component(trial_component)\n",
    "        \n",
    "        xgboost_estimator = Estimator(\n",
    "            role=role,\n",
    "            base_job_name=trial_name,\n",
    "            train_instance_count=1,\n",
    "            train_instance_type='ml.m5.xlarge',\n",
    "            image_name=container,\n",
    "            hyperparameters={\n",
    "                \"max_depth\":str(max_depth),\n",
    "                \"eta\":str(eta),\n",
    "                \"gamma\":\"4\",\n",
    "                \"min_child_weight\":\"6\",\n",
    "                \"subsample\":\"0.7\",\n",
    "                \"silent\":\"0\",\n",
    "                \"eval_metric\":\"rmse\",\n",
    "                \"objective\":\"reg:linear\",\n",
    "                \"num_round\":\"51\",\n",
    "            })\n",
    "        enable_sagemaker_metrics=True,\n",
    "        #train_use_spot_instances=True,\n",
    "        train_max_run=600,\n",
    "        train_max_wait=1200,\n",
    "        \n",
    "        debugger_hook_config=DebuggerHookConfig(\n",
    "        s3_output_path=debug_path,\n",
    "        collection_configs=[\n",
    "                CollectionConfig(\n",
    "                    name=\"metrics\",\n",
    "                    parameters={\n",
    "                        \"save_interval\":str(save_interval)\n",
    "                    }\n",
    "                ),\n",
    "                CollectionConfig(\n",
    "                    name=\"feature_importance\",\n",
    "                    parameters={\n",
    "                        \"save_interval\":str(save_interval)\n",
    "                    }\n",
    "                ),\n",
    "                CollectionConfig(\n",
    "                    name=\"full_shap\",\n",
    "                    parameters={\n",
    "                        \"save_interval\":str(save_interval)\n",
    "                    }\n",
    "                ),\n",
    "                CollectionConfig(\n",
    "                    name=\"average_shap\",\n",
    "                    parameters={\n",
    "                        \"save_interval\":str(save_interval)\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "        \n",
    "        rules=[\n",
    "            Rule.sagemaker(\n",
    "                rule_configs.loss_not_decreasing(),\n",
    "                rule_parameters={\n",
    "                    \"collection_names\":\"metrics\",\n",
    "                    \"num_steps\": str(save_interval*2),\n",
    "                },\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    xgb_training_job_name = \"xgb-training-job-{}\".format(int(time.time()))\n",
    "    \n",
    "    xgboost_estimator.fit(\n",
    "        {\"train\":train_input,\"validation\":validation_input},\n",
    "        experiment_config={\n",
    "            \"TrialName\":xgb_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\":\"Training\",\n",
    "        },\n",
    "        wait=False\n",
    "    )\n",
    "    \n",
    "    time.sleep(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Train Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\":[\n",
    "        {\n",
    "            \"Name\":\"DisplayName\",\n",
    "            \"Operator\":\"Equals\",\n",
    "            \"Value\":\"Training\",\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(sess,sm),\n",
    "    experiment_name=xgboost_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.validation:rmse.max\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=['validation:rmse'],\n",
    "    parameter_names=['max_depth','eta','silent','gamma']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df =trial_component_analytics.dataframe(force_refresh=True).sort_values([\"validation:rmse - StdDev\"])\n",
    "#check - more sort needs to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_component_name = result_df.iloc[0]['TrialComponentName']\n",
    "best_trial_component = TrialComponent.load(best_trial_component_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_trial_component.parameters['max_depth'])\n",
    "print(best_trial_component.parameters['eta'])\n",
    "print(best_trial_component.parameters['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial_component.source.source_arn.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=Session(sess,sm),\n",
    "    search_expression={\n",
    "        \"Filters\":[{\n",
    "            \"Name\":\"Parents.TrialName\",\n",
    "            \"Operator\":\"Equals\",\n",
    "            \"Value\":trial_name_map[(0.5,6)]\n",
    "        }]\n",
    "    },\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")\n",
    "\n",
    "lineage_table.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime,strftime\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\",gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model()\n",
    "scikit_learn_inferencee_model.env = {\"SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT\":\"text/csv\"}\n",
    "algo_estimator = Estimator.attach(best_trial_component.source.source_arn.split(\"/\")[-1])\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_containers = [scikit_learn_inferencee_model,best_algo_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Model Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_estimator.latest_training_job.rule_job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_estimator.latest_job_debugger_artifacts_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_track_path = os.path.join(\n",
    "    debug_path,\n",
    "    best_trial_component.source.source_arn.split(\"/\")[-1],\n",
    "    \"debug-output\")\n",
    "best_model_track_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = create_trial(best_model_track_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor(\"train-rmse\").steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor(\"validation-rmse\").values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.tensor(\"validation-rmse\").steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{i for i in trial.tensor_names() if \"average_shap\" in i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'housing_mdeian_age',\n",
    "    'total_rooms',\n",
    "    'total_bedrooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'population_per_household',\n",
    "    'bedrooms_per_room',\n",
    "    '<1H OCEAN',\n",
    "    'INLAND',\n",
    "    'ISLAND',\n",
    "    'NEAR BAY',\n",
    "    'NEAR OCEAN'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(trial,tname):\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps()\n",
    "    vals = [tensor.value(s) for s in steps]\n",
    "    return steps, vals\n",
    "\n",
    "def plot_collection(trial,collection_name,regex='.*',figsize=(8,6)):\n",
    "    fig,ax = plt.subplots(figsize=figsize)\n",
    "    sns.despine()\n",
    "    \n",
    "    print(collection_name)\n",
    "    if(collection_name == \"metrics\"):\n",
    "        tensors = trial.collection(collection_name).tensor_names\n",
    "    else:\n",
    "        tensors = {i for i in trial.tensor_names() if collection_name in i}\n",
    "     \n",
    "    for tensor_name in sorted(tensors):\n",
    "        if re.match(regex,tensor_name):\n",
    "            steps, data = get_data(trial,tensor_name)\n",
    "            if(len(tensors)) ==2:\n",
    "                label=tensor_name\n",
    "            else:\n",
    "                label= tensor_name+\"-\"+feature_names[int(tensor_name.split(\"/\")[-1].split(\"f\")[1])]\n",
    "            ax.plot(\n",
    "                steps,\n",
    "                data,\n",
    "                label=label)\n",
    "    \n",
    "    ax.legend(loc='center left',bbox_to_anchor=(1,0.5))\n",
    "    ax.set_xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(trial,importance_type=\"weight\"):\n",
    "    SUPPORTED_IMPORTANCE_TYPES=[\"Weight\",\"gain\",\"cover\",\"total_gain\",\"total_cover\"]\n",
    "    if importance_type not in SUPPORTED_IMPORTANCE_TYPES:\n",
    "        raise ValueError(f\"(importance_type) is not one of the supported importance types.\")\n",
    "    plot_collection(\n",
    "        trial,\n",
    "        \"feature_importance\",\n",
    "        regex=f\"feature_importance/{importance_type}/.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics - VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_collection(trial,\"metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cover - VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(trial,importance_type=\"cover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average SHAP - VIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_collection(trial,\"average_shap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = trial.tensor(\"full_shap/f0\").value(trial.last_complete_step)\n",
    "shap_no_base = shap_values[:,:-1]\n",
    "shap_base_value = shap_values[0,-1]\n",
    "shap.summary_plot(shap_no_base,plot_type='bar',feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{data_output_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"{data_output_path}/processed-train/processed_train_data.csv\",header=None)\n",
    "data.columns = [\"median_house_value\"]+ feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_no_base,data[['longitude',\n",
    "    'latitude',\n",
    "    'housing_mdeian_age',\n",
    "    'total_rooms',\n",
    "    'total_bedrooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'population_per_household',\n",
    "    'bedrooms_per_room',\n",
    "    '<1H OCEAN',\n",
    "    'INLAND',\n",
    "    'ISLAND',\n",
    "    'NEAR BAY',\n",
    "    'NEAR OCEAN']],feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local explanations, for a record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_base_value,shap_no_base[100,:],\n",
    "               data[['longitude',\n",
    "    'latitude',\n",
    "    'housing_mdeian_age',\n",
    "    'total_rooms',\n",
    "    'total_bedrooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'population_per_household',\n",
    "    'bedrooms_per_room',\n",
    "    '<1H OCEAN',\n",
    "    'INLAND',\n",
    "    'ISLAND',\n",
    "    'NEAR BAY',\n",
    "    'NEAR OCEAN']].iloc[100,:],link=\"identity\",matplotlib=True,text_rotation=90,figsize(20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked force plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = shap_no_base.shape[0]\n",
    "N_SAMPLES = min(100,N_ROWS)\n",
    "sampled_indices=np.random.randint(N_ROWS,size=N_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_base_value,\n",
    "                shap_no_base[sampled_indices,:],\n",
    "               data[['longitude',\n",
    "    'latitude',\n",
    "    'housing_mdeian_age',\n",
    "    'total_rooms',\n",
    "    'total_bedrooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'population_per_household',\n",
    "    'bedrooms_per_room',\n",
    "    '<1H OCEAN',\n",
    "    'INLAND',\n",
    "    'ISLAND',\n",
    "    'NEAR BAY',\n",
    "    'NEAR OCEAN']].iloc[sampled_indices,:],\n",
    "            link='identity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OUTLIERS = 3\n",
    "\n",
    "shap_sum = np.sum(shap_no_base,axis=1)\n",
    "z_scores = stats.zscore(shap_sum)\n",
    "outlier_indices = (np.argpartition(z_scores,-N_OUTLIERS)\n",
    "                  [-N_OUTLIERS:]).tolist()\n",
    "outlier_indices += (np.argpartition(z_scores,N_OUTLIERS)\n",
    "                   [:N_OUTLIERS]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fig_index,outlier_index in enumerate(outlier_indices,start=1):\n",
    "    shap.force_plot(shap_base_value,\n",
    "                   shap_no_base[outlier_index,:],\n",
    "                   data[['longitude',\n",
    "    'latitude',\n",
    "    'housing_mdeian_age',\n",
    "    'total_rooms',\n",
    "    'total_bedrooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "    'rooms_per_household',\n",
    "    'population_per_household',\n",
    "    'bedrooms_per_room',\n",
    "    '<1H OCEAN',\n",
    "    'INLAND',\n",
    "    'ISLAND',\n",
    "    'NEAR BAY',\n",
    "    'NEAR OCEAN']].iloc[outlier_index,:],\n",
    "                   matplotlib=True,\n",
    "                   link='identity',text_rotation=90,figsize=(20,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python37(assign_3)",
   "language": "python",
   "name": "assign_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
